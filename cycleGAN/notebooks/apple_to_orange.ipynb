{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGAN: Apple to Orange Translation\n",
    "\n",
    "This notebook implements CycleGAN for translating between apples and oranges using the architecture described in the [original CycleGAN paper](https://arxiv.org/abs/1703.10593). Unlike the basic tutorial, this implementation:\n",
    "\n",
    "1. Uses the ResNet generator architecture from the paper\n",
    "2. Trains for 200 epochs for better results\n",
    "3. Uses the apple-to-orange dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def preprocess_image_train(image, label):\n",
    "    image = normalize(image)\n",
    "    return image\n",
    "\n",
    "def random_crop(image):\n",
    "    image = tf.image.random_crop(image, [256, 256, 3])\n",
    "    return image\n",
    "\n",
    "def random_jitter(image):\n",
    "    # resizing to 286x286\n",
    "    image = tf.image.resize(image, [286, 286],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "    # randomly cropping to 256x256\n",
    "    image = random_crop(image)\n",
    "\n",
    "    # random mirroring\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "def preprocess_image_test(image, label):\n",
    "    image = normalize(image)\n",
    "    image = tf.image.resize(image, [256, 256],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(n_filters, input_layer):\n",
    "    \"\"\"\n",
    "    Implements a single ResNet block with two 3x3 convolutional layers\n",
    "    \"\"\"\n",
    "    # first layer\n",
    "    x = tf.keras.layers.Conv2D(n_filters, 3, padding='same', use_bias=False)(input_layer)\n",
    "    x = tfa.layers.InstanceNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = tf.keras.layers.Conv2D(n_filters, 3, padding='same', use_bias=False)(x)\n",
    "    x = tfa.layers.InstanceNormalization()(x)\n",
    "    \n",
    "    # add skip connection\n",
    "    x = tf.keras.layers.Add()([x, input_layer])\n",
    "    return x\n",
    "\n",
    "def resnet_generator(output_channels=3, dim=64, n_resnet=9, name=None):\n",
    "    \"\"\"\n",
    "    Implements the ResNet generator architecture from the CycleGAN paper\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.layers.Input(shape=[256,256,3])\n",
    "    \n",
    "    # Initial convolution\n",
    "    x = tf.keras.layers.Conv2D(dim, 7, padding='same', use_bias=False)(inputs)\n",
    "    x = tfa.layers.InstanceNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    # Downsampling\n",
    "    for _ in range(2):\n",
    "        dim *= 2\n",
    "        x = tf.keras.layers.Conv2D(dim, 3, strides=2, padding='same', use_bias=False)(x)\n",
    "        x = tfa.layers.InstanceNormalization()(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    # ResNet blocks\n",
    "    for _ in range(n_resnet):\n",
    "        x = resnet_block(dim, x)\n",
    "    \n",
    "    # Upsampling\n",
    "    for _ in range(2):\n",
    "        dim //= 2\n",
    "        x = tf.keras.layers.Conv2DTranspose(dim, 3, strides=2, padding='same', use_bias=False)(x)\n",
    "        x = tfa.layers.InstanceNormalization()(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "    \n",
    "    # Final convolution\n",
    "    x = tf.keras.layers.Conv2D(output_channels, 7, padding='same', activation='tanh')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=x, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset, metadata = tfds.load('cycle_gan/apple2orange',\n",
    "                            with_info=True, as_supervised=True)\n",
    "\n",
    "train_apples, train_oranges = dataset['trainA'], dataset['trainB']\n",
    "test_apples, test_oranges = dataset['testA'], dataset['testB']\n",
    "\n",
    "# Define constants\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "EPOCHS = 200\n",
    "LAMBDA = 10\n",
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "# Apply preprocessing\n",
    "train_apples = train_apples.map(\n",
    "    preprocess_image_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_oranges = train_oranges.map(\n",
    "    preprocess_image_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "test_apples = test_apples.map(\n",
    "    preprocess_image_test, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_oranges = test_oranges.map(\n",
    "    preprocess_image_test, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Cache, shuffle, and batch the datasets\n",
    "train_apples = train_apples.cache().shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "train_oranges = train_oranges.cache().shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "test_apples = test_apples.cache().shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_oranges = test_oranges.cache().shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generators and discriminators\n",
    "generator_g = resnet_generator(OUTPUT_CHANNELS, name='apple2orange')\n",
    "generator_f = resnet_generator(OUTPUT_CHANNELS, name='orange2apple')\n",
    "\n",
    "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
    "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
    "\n",
    "# Define optimizers\n",
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real, generated):\n",
    "    real_loss = tf.keras.losses.BinaryCrossentropy(\n",
    "        from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(real), real)\n",
    "\n",
    "    generated_loss = tf.keras.losses.BinaryCrossentropy(\n",
    "        from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.zeros_like(generated), generated)\n",
    "\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_disc_loss * 0.5\n",
    "\n",
    "def generator_loss(generated):\n",
    "    return tf.keras.losses.BinaryCrossentropy(\n",
    "        from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(generated), generated)\n",
    "\n",
    "def calc_cycle_loss(real_image, cycled_image):\n",
    "    loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "    return LAMBDA * loss1\n",
    "\n",
    "def identity_loss(real_image, same_image):\n",
    "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "    return LAMBDA * 0.5 * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_x, real_y):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Generator G translates X -> Y\n",
    "        # Generator F translates Y -> X\n",
    "\n",
    "        fake_y = generator_g(real_x, training=True)\n",
    "        cycled_x = generator_f(fake_y, training=True)\n",
    "\n",
    "        fake_x = generator_f(real_y, training=True)\n",
    "        cycled_y = generator_g(fake_x, training=True)\n",
    "\n",
    "        # same_x and same_y are used for identity loss.\n",
    "        same_x = generator_f(real_x, training=True)\n",
    "        same_y = generator_g(real_y, training=True)\n",
    "\n",
    "        disc_real_x = discriminator_x(real_x, training=True)\n",
    "        disc_real_y = discriminator_y(real_y, training=True)\n",
    "\n",
    "        disc_fake_x = discriminator_x(fake_x, training=True)\n",
    "        disc_fake_y = discriminator_y(fake_y, training=True)\n",
    "\n",
    "        # calculate the loss\n",
    "        gen_g_loss = generator_loss(disc_fake_y)\n",
    "        gen_f_loss = generator_loss(disc_fake_x)\n",
    "\n",
    "        total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_loss(real_y, cycled_y)\n",
    "\n",
    "        # Total generator loss = adversarial loss + cycle loss\n",
    "        total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)\n",
    "        total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x)\n",
    "\n",
    "        disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
    "        disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
    "\n",
    "    # Calculate the gradients for generator and discriminator\n",
    "    generator_g_gradients = tape.gradient(total_gen_g_loss, \n",
    "                                        generator_g.trainable_variables)\n",
    "    generator_f_gradients = tape.gradient(total_gen_f_loss, \n",
    "                                        generator_f.trainable_variables)\n",
    "\n",
    "    discriminator_x_gradients = tape.gradient(disc_x_loss, \n",
    "                                            discriminator_x.trainable_variables)\n",
    "    discriminator_y_gradients = tape.gradient(disc_y_loss, \n",
    "                                            discriminator_y.trainable_variables)\n",
    "\n",
    "    # Apply the gradients to the optimizers\n",
    "    generator_g_optimizer.apply_gradients(zip(generator_g_gradients, \n",
    "                                            generator_g.trainable_variables))\n",
    "    generator_f_optimizer.apply_gradients(zip(generator_f_gradients, \n",
    "                                            generator_f.trainable_variables))\n",
    "\n",
    "    discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients,\n",
    "                                                discriminator_x.trainable_variables))\n",
    "    discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients,\n",
    "                                                discriminator_y.trainable_variables))\n",
    "    \n",
    "    return {\n",
    "        \"gen_g_loss\": gen_g_loss,\n",
    "        \"gen_f_loss\": gen_f_loss,\n",
    "        \"disc_x_loss\": disc_x_loss,\n",
    "        \"disc_y_loss\": disc_y_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input):\n",
    "    prediction = model(test_input)\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "\n",
    "    display_list = [test_input[0], prediction[0]]\n",
    "    title = ['Input Image', 'Predicted Image']\n",
    "\n",
    "    for i in range(2):\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def plot_training_progress(epoch, g_losses, d_losses):\n",
    "    \"\"\"Plot training progress\"\"\"\n",
    "    plt.figure(figsize=(15,5))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(g_losses, label='Generator Loss')\n",
    "    plt.title('Generator Loss History')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(d_losses, label='Discriminator Loss')\n",
    "    plt.title('Discriminator Loss History')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    n = 0\n",
    "    for image_x, image_y in tf.data.Dataset.zip((train_apples, train_oranges)):\n",
    "        losses = train_step(image_x, image_y)\n",
    "        g_losses.append((losses['gen_g_loss'] + losses['gen_f_loss'])/2)\n",
    "        d_losses.append((losses['disc_x_loss'] + losses['disc_y_loss'])/2)\n",
    "        \n",
    "        if n % 10 == 0:\n",
    "            print('.', end='')\n",
    "        n += 1\n",
    "        \n",
    "    clear_output(wait=True)\n",
    "    # Using test_apples as example input\n",
    "    for inp in test_apples.take(1):\n",
    "        generate_images(generator_g, inp)\n",
    "        \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        plot_training_progress(epoch, g_losses, d_losses)\n",
    "    \n",
    "    print(f'Time taken for epoch {epoch + 1} is {time.time()-start} sec\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
