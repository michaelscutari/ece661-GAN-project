{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Custom Implementation: CycleGAN** \n",
    "\n",
    "Peter Banyas, Nov 13-14\n",
    "\n",
    "*Referenced two existing implementations of CycleGAN:*\n",
    "\n",
    "Aitor Ruano (@aitorzip): https://github.com/aitorzip/PyTorch-CycleGAN\n",
    "\n",
    "Jun-Yan Zhu (@junyanz): https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from datasets import ImageDataset\n",
    "import itertools\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "from visdom import Visdom\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# Structural Hyperparameters\n",
    "#####################################################\n",
    "opt = lambda: None          # creates empty object\n",
    "\n",
    "opt.epoch = 0               # epoch to start training from\n",
    "opt.num_epochs = 200        # number of epochs of training\n",
    "opt.batchSize = 1           # size of the batches\n",
    "opt.dataroot = 'data/horse2zebra'   # root directory of the dataset\n",
    "opt.lr = .0002              # initial learning rate\n",
    "opt.b1 = .5                 # momentum term of adam\n",
    "opt.b2 = .999               # adam: decay of first order momentum of gradient\n",
    "opt.decay_epoch = 100       # epoch from which to start lr decay\n",
    "opt.size = 256              # size of the data crop (squared assumed)\n",
    "opt.input_num_channels = 3  # number of channels in input images\n",
    "opt.output_num_channels = 3 # number of channels in output images\n",
    "opt.cuda = True             # use GPU?\n",
    "opt.num_cpu = 8             # number of cpu threads to use during batch generation\n",
    "\n",
    "\n",
    "#####################################################\n",
    "# Loss Function Hyperparameters (tinker with these!!)\n",
    "#####################################################\n",
    "# Which loss functions do you want?\n",
    "IDENTITY_LOSS_INCLUDED=True             # default: True (tinker with this)\n",
    "CYCLE_LOSS_INCLUDED=True                # default: True\n",
    "GAN_LOSS_INCLUDED=True                  # default: True   \n",
    "\n",
    "# How do you want to prioritize those loss functions?\n",
    "IDENTITY_WEIGHT = 5.0                   # default: 5.0\n",
    "CYCLE_WEIGHT = 10.0                     # default: 10.0\n",
    "GAN_WEIGHT = 1.0                        # default: 1.0\n",
    "\n",
    "GOOD_TRUST_DISCR_WEIGHT = 0.5           # default: 0.5\n",
    "BAD_GULLIBILITY_DISCR_WEIGHT = 0.5      # default: 0.5\n",
    "\n",
    "#####################################################\n",
    "#  WHERE TO SAVE THE MODEL\n",
    "#####################################################\n",
    "SUBFOLDER_FOR_SAVING_MODELS = 'nov14_with_special_loss'  # ex: 'nov14_with_special_loss'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Translators\n",
    "\n",
    "### *this oddly doesn't include ReLU at ResBlock output...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.local_route = nn.Sequential(\n",
    "            # padding largens image; conv reduces it back to original size.\n",
    "            nn.ReflectionPad2d(1), # adds one-pixel border around image (reflected outwards)\n",
    "            nn.Conv2d(in_features, in_features, 3), #in_channels=out_channels bc it's the same image channels in & out.  3x3 Kernel.\n",
    "            nn.InstanceNorm2d(in_features), #normalizes the input per channel\n",
    "            \n",
    "            nn.ReLU(inplace=True), #\"inplace\" :. will modify the input directly, w/o allocating additional output. memory efficient.\n",
    "            \n",
    "            nn.ReflectionPad2d(1), \n",
    "            nn.Conv2d(in_features, in_features, 3),\n",
    "            nn.InstanceNorm2d(in_features)\n",
    "\n",
    "            # no ReLU here.  ReLU is applied after sum of local_route & highway\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.local_route(x) # x bypasses local_route (residual) to help backpropagation.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_num_channels, output_num_channels, n_residual_blocks=9):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        ## Initial Convolution Block\n",
    "        model = [ \n",
    "            nn.ReflectionPad2d(3), #adds 3-pixel border (reflected outwards)\n",
    "            nn.Conv2d(input_num_channels, 64, 7), #extracts 64 diff features using 7x7 kernel\n",
    "            nn.InstanceNorm2d(64), #normalize data along each channel\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "\n",
    "        ## Downsample\n",
    "        in_features = 64\n",
    "        out_features = in_features * 2\n",
    "        for _ in range(2):              # 2 downsampling layers\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1), #doubles features; halves image size\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features * 2\n",
    "\n",
    "        ## Residual Blocks\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResidualBlock(out_features)] # processing in deep feature space\n",
    "\n",
    "        ## Upsample\n",
    "        out_features = in_features // 2\n",
    "        for _ in range(2):              # 2 upsampling layers\n",
    "            model += [\n",
    "                nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1), #halves features; doubles image size\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features // 2\n",
    "\n",
    "        ## Output Layer\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(64, output_num_channels, 7),\n",
    "            nn.Tanh() #squashes output to [-1, 1]\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_num_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        ## Multiple convolutions\n",
    "        model = [\n",
    "            nn.Conv2d(input_num_channels, 64, 4, stride=2, padding=1), # 64 features, 4x4 kernel, ~halves image size\n",
    "            nn.LeakyReLU(.2, inplace=True), #slope of negative part is y=.2x\n",
    "        ]\n",
    "        model += [\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1), # double features, half image size\n",
    "            nn.InstanceNorm2d(128), # norms per channel\n",
    "            nn.LeakyReLU(.2, inplace=True)\n",
    "        ]\n",
    "        model += [\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1), #double features, half image size\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(.2, inplace=True)\n",
    "        ]\n",
    "        model += [\n",
    "            nn.Conv2d(256, 512, 4, stride=2, padding=1), #double features, half image size\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(.2, inplace=True)\n",
    "        ]\n",
    "\n",
    "        ## FullyConvNet classification layer\n",
    "        model += [\n",
    "            nn.Conv2d(512, 1, 4, padding=1) # report one feature, well-informed by 512 features\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create instances of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_X_to_Y = Generator(3, 3) # \"G\" in the paper\n",
    "gen_Y_to_X = Generator(3, 3) # \"F\"\n",
    "\n",
    "discr_Y = Discriminator(3) # \"D_y\" in the paper\n",
    "discr_X = Discriminator(3) # \"D_x\"\n",
    "\n",
    "if opt.cuda:\n",
    "    gen_X_to_Y = gen_X_to_Y.cuda()\n",
    "    gen_Y_to_X = gen_Y_to_X.cuda()\n",
    "    discr_X = discr_X.cuda()\n",
    "    discr_Y = discr_Y.cuda()\n",
    "    \n",
    "# Initialize weights\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "gen_X_to_Y.apply(weights_init_normal)\n",
    "gen_Y_to_X.apply(weights_init_normal)\n",
    "\n",
    "discr_X.apply(weights_init_normal)\n",
    "discr_Y.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOSSES\n",
    "criterion_identity = nn.L1Loss()\n",
    "criterion_cycle = nn.L1Loss()\n",
    "criterion_GAN = nn.MSELoss()\n",
    "\n",
    "##############################################################################################\n",
    "## Optimizers, Learning Rate Schedulers\n",
    "##############################################################################################\n",
    "optimizer_gen_XY = optim.Adam(itertools.chain(gen_X_to_Y.parameters(), gen_Y_to_X.parameters()),\n",
    "                                 lr = opt.lr, betas = (opt.b1, opt.b2))\n",
    "optimizer_gen_YX = optim.Adam(itertools.chain(gen_X_to_Y.parameters(), gen_Y_to_X.parameters()),\n",
    "                                 lr = opt.lr, betas = (opt.b1, opt.b2))\n",
    "optimizer_discr_X = optim.Adam(discr_X.parameters(), lr = opt.lr, betas = (opt.b1, opt.b2))\n",
    "optimizer_discr_Y = optim.Adam(discr_Y.parameters(), lr = opt.lr, betas = (opt.b1, opt.b2))\n",
    "\n",
    "class LambdaLR():\n",
    "    def __init__(self, num_epochs, offset, decay_start_epoch):\n",
    "        assert ((num_epochs - decay_start_epoch) > 0), \"Decay must start before the training session ends!\"\n",
    "        self.num_epochs = num_epochs\n",
    "        self.offset = offset\n",
    "        self.decay_start_epoch = decay_start_epoch\n",
    "    def step(self, epoch):\n",
    "        # learning rate linearly decays from 1 to 0 after the decay starts\n",
    "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch) / (self.num_epochs - self.decay_start_epoch)\n",
    "\n",
    "lr_scheduler_gen_XY = optim.lr_scheduler.LambdaLR(optimizer_gen_XY, lr_lambda=LambdaLR(opt.num_epochs, opt.epoch, opt.decay_epoch).step)\n",
    "lr_scheduler_gen_YX = optim.lr_scheduler.LambdaLR(optimizer_gen_YX, lr_lambda=LambdaLR(opt.num_epochs, opt.epoch, opt.decay_epoch).step)\n",
    "\n",
    "lr_scheduler_discr_X = optim.lr_scheduler.LambdaLR(optimizer_discr_X, lr_lambda=LambdaLR(opt.num_epochs, opt.epoch, opt.decay_epoch).step)\n",
    "lr_scheduler_discr_Y = optim.lr_scheduler.LambdaLR(optimizer_discr_Y, lr_lambda=LambdaLR(opt.num_epochs, opt.epoch, opt.decay_epoch).step)\n",
    "\n",
    "##############################################################################################\n",
    "## Inputs, memory allocation\n",
    "##############################################################################################\n",
    "# Tensor = torch.cuda.FloatTensor if opt.cuda else torch.Tensor\n",
    "# input_X = Tensor(opt.batchSize, opt.input_num_channels, opt.size, opt.size)\n",
    "# input_Y = Tensor(opt.batchSize, opt.input_num_channels, opt.size, opt.size)\n",
    "# target_real = torch.ones((input_image.size(0), 1, 30, 30), device=device)\n",
    "# target_fake = torch.zeros((input_image.size(0), 1, 30, 30), device=device)\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size=50):\n",
    "        assert (max_size > 0), \"Buffer size must be greater than 0\"\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data:\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            if len(self.data) < self.max_size: # if there's space in buffer, add element\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else:\n",
    "                if torch.rand(1).item() > .5: # 50% chance\n",
    "                    i = torch.randint(0, self.max_size, (1,)).item() # pick random element to replace\n",
    "                    to_return.append(self.data[i].clone()) # return the element we're replacing\n",
    "                    self.data[i] = element # fill in the spot\n",
    "                else:  # other 50% of time\n",
    "                    to_return.append(element)\n",
    "        return torch.cat(to_return)\n",
    "    \n",
    "fake_X_buffer = ReplayBuffer()\n",
    "fake_Y_buffer = ReplayBuffer()\n",
    "\n",
    "##############################################################################################\n",
    "## Dataset loader\n",
    "##############################################################################################\n",
    "dataloader = DataLoader(ImageDataset(opt.dataroot, \n",
    "                                    transforms=Config.transform\n",
    "                                    unaligned=True),\n",
    "                                    batch_size=opt.batchSize, \n",
    "                                    shuffle=True, \n",
    "                                    num_workers=opt.num_cpu)\n",
    "\n",
    "##############################################################################################\n",
    "## Loss plot\n",
    "##############################################################################################\n",
    "def tensor2image(tensor):\n",
    "    image = 127.5*(tensor[0].cpu().float().numpy() + 1.0)\n",
    "    if image.shape[0] == 1:\n",
    "        image = np.tile(image, (3,1,1))\n",
    "    return image.astype(np.uint8)\n",
    "\n",
    "class Logger():\n",
    "    def __init__(self, n_epochs, batches_epoch):\n",
    "        self.viz = Visdom()\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batches_epoch = batches_epoch\n",
    "        self.epoch = 1\n",
    "        self.batch = 1\n",
    "        self.prev_time = time.time()\n",
    "        self.mean_period = 0\n",
    "        self.losses = {}\n",
    "        self.loss_windows = {}\n",
    "        self.image_windows = {}\n",
    "\n",
    "\n",
    "    def log(self, losses=None, images=None):\n",
    "        self.mean_period += (time.time() - self.prev_time)\n",
    "        self.prev_time = time.time()\n",
    "\n",
    "        sys.stdout.write('\\rEpoch %03d/%03d [%04d/%04d] -- ' % (self.epoch, self.n_epochs, self.batch, self.batches_epoch))\n",
    "\n",
    "        for i, loss_name in enumerate(losses.keys()):\n",
    "            if loss_name not in self.losses:\n",
    "                self.losses[loss_name] = losses[loss_name].data[0]\n",
    "            else:\n",
    "                self.losses[loss_name] += losses[loss_name].data[0]\n",
    "\n",
    "            if (i+1) == len(losses.keys()):\n",
    "                sys.stdout.write('%s: %.4f -- ' % (loss_name, self.losses[loss_name]/self.batch))\n",
    "            else:\n",
    "                sys.stdout.write('%s: %.4f | ' % (loss_name, self.losses[loss_name]/self.batch))\n",
    "\n",
    "        batches_done = self.batches_epoch*(self.epoch - 1) + self.batch\n",
    "        batches_left = self.batches_epoch*(self.n_epochs - self.epoch) + self.batches_epoch - self.batch \n",
    "        sys.stdout.write('ETA: %s' % (datetime.timedelta(seconds=batches_left*self.mean_period/batches_done)))\n",
    "\n",
    "        # Draw images\n",
    "        for image_name, tensor in images.items():\n",
    "            if image_name not in self.image_windows:\n",
    "                self.image_windows[image_name] = self.viz.image(tensor2image(tensor.data), opts={'title':image_name})\n",
    "            else:\n",
    "                self.viz.image(tensor2image(tensor.data), win=self.image_windows[image_name], opts={'title':image_name})\n",
    "\n",
    "        # End of epoch\n",
    "        if (self.batch % self.batches_epoch) == 0:\n",
    "            # Plot losses\n",
    "            for loss_name, loss in self.losses.items():\n",
    "                if loss_name not in self.loss_windows:\n",
    "                    self.loss_windows[loss_name] = self.viz.line(X=np.array([self.epoch]), Y=np.array([loss/self.batch]), \n",
    "                                                                    opts={'xlabel': 'epochs', 'ylabel': loss_name, 'title': loss_name})\n",
    "                else:\n",
    "                    self.viz.line(X=np.array([self.epoch]), Y=np.array([loss/self.batch]), win=self.loss_windows[loss_name], update='append')\n",
    "                # Reset losses for next epoch\n",
    "                self.losses[loss_name] = 0.0\n",
    "\n",
    "            self.epoch += 1\n",
    "            self.batch = 1\n",
    "            sys.stdout.write('\\n')\n",
    "        else:\n",
    "            self.batch += 1\n",
    "\n",
    "logger = Logger(opt.num_epochs, len(dataloader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(opt.epoch, opt.num_epochs):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "\n",
    "        # Pull in the real images\n",
    "        real_X = Variable(input_X.copy_(batch['A']))  ## ALERT ALERT may need to change 'A' to 'X' \n",
    "        real_Y = Variable(input_Y.copy_(batch['B']))\n",
    "\n",
    "        ################################################################################################\n",
    "        # Generator \n",
    "        ################################################################################################\n",
    "\n",
    "        # Activate the generators\n",
    "        optimizer_gen.zero_grad() # start with zero gradients\n",
    "\n",
    "        ################################################\n",
    "        #### Identity Loss (oOooh controversial)\n",
    "        ################################################\n",
    "        # tests if the generator won't change images that are already output-type\n",
    "        # that Gen[x->y](Y) => Y\n",
    "        # generator only.  NO discriminator involved.\n",
    "        if IDENTITY_LOSS_INCLUDED == True:\n",
    "            allegedly_same_Y = gen_X_to_Y(real_Y) # G(Y) should remain Y\n",
    "            loss_identity_Y = criterion_identity(allegedly_same_Y, real_Y)\n",
    "\n",
    "            allegedly_same_X = gen_Y_to_X(real_X) # G(X) should remain X\n",
    "            loss_identity_X = criterion_identity(allegedly_same_X, real_X)\n",
    "        else:\n",
    "            loss_identity_Y = 0\n",
    "            loss_identity_X = 0\n",
    "\n",
    "        ################################################\n",
    "        #### GAN Loss\n",
    "        ################################################\n",
    "        # tests if the Generator can trick the Discriminator\n",
    "        # by making a sufficiently realistic image.\n",
    "\n",
    "        # When Discr_y(INPUT) = 1, it thinks INPUT == real.\n",
    "        # When Discr_y(INPUT) = 0, it thinks INPUT == fake.\n",
    "\n",
    "        # :. if Discr_y( Gen[x->y](X) ) == 1, then the generator has successfully tricked the discriminator :. loss for the generator should be low.\n",
    "        #    if Discr_y( Gen[x->y](X) ) == 0, then the generator has failed to trick the discriminator :. loss for the generator should be high.\n",
    "\n",
    "        if GAN_LOSS_INCLUDED == True:\n",
    "            fake_Y = gen_X_to_Y(real_X)\n",
    "            gullibility_to_fake_Y = discr_Y(fake_Y) # 1: tricked that fake_Y is real. 0: realizes fake_Y is fake \n",
    "            loss_GAN_Y = criterion_GAN(gullibility_to_fake_Y, target_real) # how far away from 1 are we (low loss if Generator can trick Discriminator)\n",
    "\n",
    "            fake_X = gen_Y_to_X(real_Y)\n",
    "            gullibility_to_fake_X = discr_X(fake_X) # 1: tricked that fake_X is real. 0: realizes fake_X is fake\n",
    "            loss_GAN_X = criterion_GAN(gullibility_to_fake_X, target_real)\n",
    "        else:\n",
    "            loss_GAN_Y = 0\n",
    "            loss_GAN_X = 0\n",
    "\n",
    "        ################################################\n",
    "        #### Cycle Consistency Loss\n",
    "        ################################################\n",
    "        # tests if the generators are symmetric & \n",
    "        # can they reconstruct the original image from the transformed image?\n",
    "        # that Gen[y->x]( Gen[x->y](X) ) == X\n",
    "\n",
    "        # generator only.  NO discriminator involved.\n",
    "\n",
    "        if CYCLE_LOSS_INCLUDED == True:\n",
    "            allegedly_reconstructed_X = gen_Y_to_X(fake_Y) # complete the cycle\n",
    "            loss_cycle_X = criterion_cycle(allegedly_reconstructed_X, real_X)\n",
    "\n",
    "            allegedly_reconstructed_Y = gen_X_to_Y(fake_X) # complete the cycle\n",
    "            loss_cycle_Y = criterion_cycle(allegedly_reconstructed_Y, real_Y)\n",
    "        else:\n",
    "            loss_cycle_X = 0\n",
    "            loss_cycle_Y = 0\n",
    "\n",
    "\n",
    "        ################################################\n",
    "        #### TOTAL Loss\n",
    "        ################################################\n",
    "        loss_gen = IDENTITY_WEIGHT*(loss_identity_X + loss_identity_Y)\n",
    "        loss_gen += GAN_WEIGHT*(loss_GAN_X + loss_GAN_Y)\n",
    "        loss_gen += CYCLE_WEIGHT*(loss_cycle_X + loss_cycle_Y)\n",
    "        loss_gen.backward()\n",
    "\n",
    "        optimizer_gen.step()\n",
    "        \n",
    "        \n",
    "        ################################################################################################\n",
    "        # Discriminator \n",
    "        ################################################################################################\n",
    "\n",
    "        # Activate the discriminators\n",
    "        optimizer_discr_X.zero_grad()\n",
    "        optimizer_discr_Y.zero_grad()\n",
    "\n",
    "        ################################################\n",
    "        #### Appreciate Truth\n",
    "        ################################################\n",
    "\n",
    "        faith_in_true_X = discr_X(real_X) # 1: properly recognizes that real_X is real. 0: mistakenly judges real_X as fake\n",
    "        faith_in_true_Y = discr_Y(real_Y)\n",
    "\n",
    "        loss_discr_X_real = criterion_GAN(faith_in_true_X, target_real) # how far away from 1 are we (low loss if Discriminator properly identifies real images as real)\n",
    "        loss_discr_Y_real = criterion_GAN(faith_in_true_Y, target_real) # can Discr tell real images are real?\n",
    "        # rewards 1, punishes 0.\n",
    "\n",
    "        ################################################\n",
    "        #### Reject Fiction\n",
    "        ################################################\n",
    "\n",
    "        fake_X = fake_X_buffer.push_and_pop(fake_X) # get a new fake image\n",
    "        fake_Y = fake_Y_buffer.push_and_pop(fake_Y)\n",
    "        \n",
    "        gullibility_to_fake_X_2 = discr_X(fake_X.detach()) # detach to avoid backpropagation                                # ALERT ALERT why is this the only one with .DETACH()\n",
    "        gullibility_to_fake_Y_2 = discr_Y(fake_Y.detach()) # 1: tricked that fake_X is real. 0: realizes fake_X is fake\n",
    "        \n",
    "        loss_discr_X_fake = criterion_GAN(gullibility_to_fake_X_2, target_fake) # how far away from 0 are we (low loss if Discriminator properly identifies fake images as fake)\n",
    "        loss_discr_Y_fake  = criterion_GAN(gullibility_to_fake_Y_2, target_fake)\n",
    "        # rewards 0, punishes 1.\n",
    "\n",
    "        ################################################\n",
    "        #### TOTAL Loss\n",
    "        ################################################\n",
    "        loss_discr_X = GOOD_TRUST_DISCR_WEIGHT * loss_discr_X_real\n",
    "        loss_discr_X += BAD_GULLIBILITY_DISCR_WEIGHT *loss_discr_X_fake\n",
    "\n",
    "        loss_discr_Y = GOOD_TRUST_DISCR_WEIGHT * loss_discr_Y_real\n",
    "        loss_discr_Y += BAD_GULLIBILITY_DISCR_WEIGHT * loss_discr_Y_fake\n",
    "\n",
    "        loss_discr_X.backward()\n",
    "        loss_discr_Y.backward()\n",
    "\n",
    "        optimizer_discr_X.step()        # WARNING I did this with X & Y in parallel. other implementations have all X stuff, then all Y stuff.\n",
    "        optimizer_discr_Y.step()\n",
    "\n",
    "        ################################################################################################\n",
    "        # Progress Report \n",
    "        ################################################################################################\n",
    "        logger.log({\n",
    "            #### Generator Losses\n",
    "            'loss_GAN_X': loss_GAN_X,\n",
    "            'loss_GAN_Y': loss_GAN_Y,\n",
    "            'loss_cycle_X': loss_cycle_X,\n",
    "            'loss_cycle_Y': loss_cycle_Y,\n",
    "            'loss_identity_X': loss_identity_X,\n",
    "            'loss_identity_Y': loss_identity_Y,\n",
    "            # Total Generator Loss\n",
    "            'loss_gen': loss_gen,\n",
    "\n",
    "            #### Discriminator Losses\n",
    "            'loss_discr_X_real': loss_discr_X_real,\n",
    "            'loss_discr_Y_real': loss_discr_Y_real,\n",
    "            'loss_discr_X_fake': loss_discr_X_fake,\n",
    "            'loss_discr_Y_fake': loss_discr_Y_fake,\n",
    "            # Total Discriminator Loss\n",
    "            'loss_discr_X': loss_discr_X,\n",
    "            'loss_discr_Y': loss_discr_Y\n",
    "        }, \n",
    "        images={\n",
    "            'real_X': real_X,\n",
    "            'real_Y': real_Y,\n",
    "            'fake_X': fake_X,\n",
    "            'fake_Y': fake_Y\n",
    "            'allegedly_reconstructed_X': allegedly_reconstructed_X,\n",
    "            'allegedly_reconstructed_Y': allegedly_reconstructed_Y\n",
    "        })\n",
    "\n",
    "    # Update Learning Rates\n",
    "    lr_scheduler_gen.step()\n",
    "    lr_scheduler_discr_X.step()\n",
    "    lr_scheduler_discr_Y.step()\n",
    "\n",
    "    # Save Model Checkpoints\n",
    "    torch.save(gen_X_to_Y.state_dict(), f'saved_models/{SUBFOLDER_FOR_SAVING_MODELS}/gen_X_to_Y_epoch{epoch+1}.pth')\n",
    "    torch.save(gen_Y_to_X.state_dict(), f'saved_models/{SUBFOLDER_FOR_SAVING_MODELS}/gen_Y_to_X_epoch{epoch+1}.pth')\n",
    "    torch.save(discr_X.state_dict(), f'saved_models/{SUBFOLDER_FOR_SAVING_MODELS}/discr_X_epoch{epoch+1}.pth')\n",
    "    torch.save(discr_Y.state_dict(), f'saved_models/{SUBFOLDER_FOR_SAVING_MODELS}/discr_Y_epoch{epoch+1}.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
