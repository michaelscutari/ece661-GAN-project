{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peter Banyas | Nov 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from datasets import ImageDataset\n",
    "import itertools\n",
    "\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "from visdom import Visdom\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Translators\n",
    "\n",
    "## **WHY DO THE IMPLEMENTATIONS FORGET RELU at OUTPUT???**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.local_route = nn.Sequential(\n",
    "            # padding largens image; conv reduces it back to original size.\n",
    "            nn.ReflectionPad2d(1), # adds one-pixel border around image (reflected outwards)\n",
    "            nn.Conv2d(in_features, in_features, 3), #in_channels=out_channels bc it's the same image channels in & out.  3x3 Kernel.\n",
    "            nn.InstanceNorm2d(in_features), #normalizes the input per channel\n",
    "            \n",
    "            nn.ReLU(inplace=True), #\"inplace\" :. will modify the input directly, w/o allocating additional output. memory efficient.\n",
    "            \n",
    "            nn.ReflectionPad2d(1), \n",
    "            nn.Conv2d(in_features, in_features, 3),\n",
    "            nn.InstanceNorm2d(in_features)\n",
    "\n",
    "            # no ReLU here.  ReLU is applied after sum of local_route & highway\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.local_route(x) # x bypasses local_route (residual) to help backpropagation.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_num_channels, output_num_channels, n_residual_blocks=9):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        ## Initial Convolution Block\n",
    "        model = [ \n",
    "            nn.ReflectionPad2d(3), #adds 3-pixel border (reflected outwards)\n",
    "            nn.Conv2d(input_num_channels, 64, 7), #extracts 64 diff features using 7x7 kernel\n",
    "            nn.InstanceNorm2d(64), #normalize data along each channel\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "\n",
    "        ## Downsample\n",
    "        in_features = 64\n",
    "        out_features = in_features * 2\n",
    "        for _ in range(2):              # 2 downsampling layers\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1), #doubles features; halves image size\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features * 2\n",
    "\n",
    "        ## Residual Blocks\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResidualBlock(out_features)] # processing in deep feature space\n",
    "\n",
    "        ## Upsample\n",
    "        out_features = in_features // 2\n",
    "        for _ in range(2):              # 2 upsampling layers\n",
    "            model += [\n",
    "                nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1), #halves features; doubles image size\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features // 2\n",
    "\n",
    "        ## Output Layer\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(64, output_num_channels, 7),\n",
    "            nn.Tanh() #squashes output to [-1, 1]\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_num_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        ## Multiple convolutions\n",
    "        model = [\n",
    "            nn.Conv2d(input_num_channels, 64, 4, stride=2, padding=1), # 64 features, 4x4 kernel, ~halves image size\n",
    "            nn.LeakyReLU(.2, inplace=True), #slope of negative part is y=.2x\n",
    "        ]\n",
    "        model += [\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1), # double features, half image size\n",
    "            nn.InstanceNorm2d(128), # norms per channel\n",
    "            nn.LeakyReLU(.2, inplace=True)\n",
    "        ]\n",
    "        model += [\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1), #double features, half image size\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(.2, inplace=True)\n",
    "        ]\n",
    "        model += [\n",
    "            nn.Conv2d(256, 512, 4, stride=2, padding=1), #double features, half image size\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(.2, inplace=True)\n",
    "        ]\n",
    "\n",
    "        ## FullyConvNet classification layer\n",
    "        model += [\n",
    "            nn.Conv2d(512, 1, 4, padding=1) # report one feature, well-informed by 512 features\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create instances of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_X_to_Y = Generator(3, 3) # \"G\"\n",
    "gen_Y_to_X = Generator(3, 3) # \"F\"\n",
    "\n",
    "discr_Y = Discriminator(3) # \"D_y\"\n",
    "discr_X = Discriminator(3) # \"D_x\"\n",
    "\n",
    "if opt.cuda:\n",
    "    gen_X_to_Y = gen_X_to_Y.cuda()\n",
    "    gen_Y_to_X = gen_Y_to_X.cuda()\n",
    "    discr_X = discr_X.cuda()\n",
    "    discr_Y = discr_Y.cuda()\n",
    "    \n",
    "# Initialize weights\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "gen_X_to_Y.apply(weights_init_normal)\n",
    "gen_Y_to_X.apply(weights_init_normal)\n",
    "\n",
    "discr_X.apply(weights_init_normal)\n",
    "discr_Y.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss_adversarial(X, Y, fake_X, fake_Y)\n",
    "#     catch_fake_Y = ( discr_Y(gen_X_to_Y(X)) - 1 )**2\n",
    "#     catch_fake_X = ( discr_X(gen_Y_to_X(Y)) - 1 )**2\n",
    "#     appreciate_true_Y = ( discr_Y(Y) - 1 )**2\n",
    "#     appreciate_true_X = ( discr_X(X) - 1 )**2\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HYPERPARAMETERS\n",
    "opt = lambda: None\n",
    "\n",
    "opt.epoch = 0\n",
    "opt.num_epochs = 200\n",
    "opt.batchSize = 1\n",
    "opt.dataroot = 'datasets/horse2zebra'\n",
    "opt.lr = .0002\n",
    "opt.b1 = .5\n",
    "opt.b2 = .999\n",
    "opt.decay_epoch = 100\n",
    "opt.size = 256\n",
    "opt.input_num_channels = 3\n",
    "opt.output_num_channels = 3\n",
    "opt.cuda = True\n",
    "opt.num_cpu = 8\n",
    "\n",
    "IDENTITY_WEIGHT = 5.0\n",
    "CYCLE_WEIGHT = 10.0\n",
    "ADVERSARIAL_WEIGHT = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOSSES\n",
    "criterion_identity = nn.L1Loss()\n",
    "criterion_cycle = nn.L1Loss()\n",
    "criterion_GAN = nn.MSELoss()\n",
    "\n",
    "##############################################################################################\n",
    "## Optimizers, Learning Rate Schedulers\n",
    "##############################################################################################\n",
    "optimizer_gen = optim.Adam(itertools.chain(gen_X_to_Y.parameters(), gen_Y_to_X.parameters()),\n",
    "                                 lr = opt.lr, betas = (opt.b1, opt.b2))\n",
    "optimizer_discr_X = optim.Adam(discr_X.parameters(), lr = opt.lr, betas = (opt.b1, opt.b2))\n",
    "optimizer_discr_Y = optim.Adam(discr_Y.parameters(), lr = opt.lr, betas = (opt.b1, opt.b2))\n",
    "\n",
    "class LambdaLR():\n",
    "    def __init__(self, num_epochs, offset, decay_start_epoch):\n",
    "        assert ((num_epochs - decay_start_epoch) > 0), \"Decay must start before the training session ends!\"\n",
    "        self.num_epochs = num_epochs\n",
    "        self.offset = offset\n",
    "        self.decay_start_epoch = decay_start_epoch\n",
    "    def step(self, epoch):\n",
    "        # learning rate linearly decays from 1 to 0 after the decay starts\n",
    "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch) / (self.num_epochs - self.decay_start_epoch)\n",
    "\n",
    "lr_scheduler_gen = optim.lr_scheduler.LambdaLR(optimizer_gen, lr_lambda=LambdaLR(opt.num_epochs, opt.epoch, opt.decay_epoch).step)\n",
    "lr_scheduler_discr_X = optim.lr_scheduler.LambdaLR(optimizer_discr_X, lr_lambda=LambdaLR(opt.num_epochs, opt.epoch, opt.decay_epoch).step)\n",
    "lr_scheduler_discr_Y = optim.lr_scheduler.LambdaLR(optimizer_discr_Y, lr_lambda=LambdaLR(opt.num_epochs, opt.epoch, opt.decay_epoch).step)\n",
    "\n",
    "##############################################################################################\n",
    "## Inputs, memory allocation\n",
    "##############################################################################################\n",
    "Tensor = torch.cuda.FloatTensor if opt.cuda else torch.Tensor\n",
    "input_X = Tensor(opt.batchSize, opt.input_num_channels, opt.size, opt.size)\n",
    "input_Y = Tensor(opt.batchSize, opt.input_num_channels, opt.size, opt.size)\n",
    "target_real = Variable(Tensor(opt.batchSize).fill_(1.0), requires_grad=False) # bunch of 1s we can compare against the discriminator outputs\n",
    "target_fake = Variable(Tensor(opt.batchSize).fill_(0.0), requires_grad=False) # bunch of 0s ^\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size=50):\n",
    "        assert (max_size > 0), \"Buffer size must be greater than 0\"\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data:\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            if len(self.data) < self.max_size: # if there's space in buffer, add element\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else:\n",
    "                if torch.rand(1).item() > .5: # 50% chance\n",
    "                    i = torch.randint(0, self.max_size, (1,)).item() # pick random element to replace\n",
    "                    to_return.append(self.data[i].clone()) # return the element we're replacing\n",
    "                    self.data[i] = element # fill in the spot\n",
    "                else:  # other 50% of time\n",
    "                    to_return.append(element)\n",
    "        return Variable(torch.cat(to_return))\n",
    "    \n",
    "fake_X_buffer = ReplayBuffer()\n",
    "fake_Y_buffer = ReplayBuffer()\n",
    "\n",
    "##############################################################################################\n",
    "## Dataset loader\n",
    "##############################################################################################\n",
    "dataloader = DataLoader(ImageDataset(opt.dataroot, \n",
    "                                     tranfroms_= [\n",
    "                                         transforms.Resize(int(opt.size * 1.12), Image.BICUBIC),\n",
    "                                         transforms.RandomCrop(opt.size),\n",
    "                                         transforms.RandomHorizontalFlip(),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "                                         ],\n",
    "                                      unaligned=True),\n",
    "                                      batch_size=opt.batchSize, \n",
    "                                      shuffle=True, \n",
    "                                      num_workers=opt.num_cpu)\n",
    "\n",
    "##############################################################################################\n",
    "## Loss plot\n",
    "##############################################################################################\n",
    "def tensor2image(tensor):\n",
    "    image = 127.5*(tensor[0].cpu().float().numpy() + 1.0)\n",
    "    if image.shape[0] == 1:\n",
    "        image = np.tile(image, (3,1,1))\n",
    "    return image.astype(np.uint8)\n",
    "\n",
    "class Logger():\n",
    "    def __init__(self, n_epochs, batches_epoch):\n",
    "        self.viz = Visdom()\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batches_epoch = batches_epoch\n",
    "        self.epoch = 1\n",
    "        self.batch = 1\n",
    "        self.prev_time = time.time()\n",
    "        self.mean_period = 0\n",
    "        self.losses = {}\n",
    "        self.loss_windows = {}\n",
    "        self.image_windows = {}\n",
    "\n",
    "\n",
    "    def log(self, losses=None, images=None):\n",
    "        self.mean_period += (time.time() - self.prev_time)\n",
    "        self.prev_time = time.time()\n",
    "\n",
    "        sys.stdout.write('\\rEpoch %03d/%03d [%04d/%04d] -- ' % (self.epoch, self.n_epochs, self.batch, self.batches_epoch))\n",
    "\n",
    "        for i, loss_name in enumerate(losses.keys()):\n",
    "            if loss_name not in self.losses:\n",
    "                self.losses[loss_name] = losses[loss_name].data[0]\n",
    "            else:\n",
    "                self.losses[loss_name] += losses[loss_name].data[0]\n",
    "\n",
    "            if (i+1) == len(losses.keys()):\n",
    "                sys.stdout.write('%s: %.4f -- ' % (loss_name, self.losses[loss_name]/self.batch))\n",
    "            else:\n",
    "                sys.stdout.write('%s: %.4f | ' % (loss_name, self.losses[loss_name]/self.batch))\n",
    "\n",
    "        batches_done = self.batches_epoch*(self.epoch - 1) + self.batch\n",
    "        batches_left = self.batches_epoch*(self.n_epochs - self.epoch) + self.batches_epoch - self.batch \n",
    "        sys.stdout.write('ETA: %s' % (datetime.timedelta(seconds=batches_left*self.mean_period/batches_done)))\n",
    "\n",
    "        # Draw images\n",
    "        for image_name, tensor in images.items():\n",
    "            if image_name not in self.image_windows:\n",
    "                self.image_windows[image_name] = self.viz.image(tensor2image(tensor.data), opts={'title':image_name})\n",
    "            else:\n",
    "                self.viz.image(tensor2image(tensor.data), win=self.image_windows[image_name], opts={'title':image_name})\n",
    "\n",
    "        # End of epoch\n",
    "        if (self.batch % self.batches_epoch) == 0:\n",
    "            # Plot losses\n",
    "            for loss_name, loss in self.losses.items():\n",
    "                if loss_name not in self.loss_windows:\n",
    "                    self.loss_windows[loss_name] = self.viz.line(X=np.array([self.epoch]), Y=np.array([loss/self.batch]), \n",
    "                                                                    opts={'xlabel': 'epochs', 'ylabel': loss_name, 'title': loss_name})\n",
    "                else:\n",
    "                    self.viz.line(X=np.array([self.epoch]), Y=np.array([loss/self.batch]), win=self.loss_windows[loss_name], update='append')\n",
    "                # Reset losses for next epoch\n",
    "                self.losses[loss_name] = 0.0\n",
    "\n",
    "            self.epoch += 1\n",
    "            self.batch = 1\n",
    "            sys.stdout.write('\\n')\n",
    "        else:\n",
    "            self.batch += 1\n",
    "\n",
    "logger = Logger(opt.num_epochs, len(dataloader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(opt.epoch, opt.num_epochs):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "\n",
    "        # Pull in the real images\n",
    "        real_X = Variable(input_X.copy_(batch['A']))  ## ALERT ALERT may need to change 'A' to 'X' \n",
    "        real_Y = Variable(input_Y.copy_(batch['B']))\n",
    "\n",
    "        # Activate the generators\n",
    "        optimizer_gen.zero_grad() # start with zero gradients\n",
    "\n",
    "        #### Identity Loss\n",
    "        allegedly_same_Y = gen_X_to_Y(real_Y) # G(Y) should remain Y\n",
    "        loss_identity_Y = criterion_identity(allegedly_same_Y, real_Y) * IDENTITY_WEIGHT\n",
    "\n",
    "        allegedly_same_X = gen_Y_to_X(real_X) # G(X) should remain X\n",
    "        loss_identity_X = criterion_identity(allegedly_same_X, real_X) * IDENTITY_WEIGHT\n",
    "\n",
    "        #### GAN Loss\n",
    "        fake_Y = gen_X_to_Y(real_X)\n",
    "        gullibility_to_fake_Y = discr_Y(fake_Y) # 1: tricked that fake_Y is real. 0: realizes fake_Y is fake  ## ALERT ALERT is this true\n",
    "        loss_GAN_Y = criterion_GAN(gullibility_to_fake_Y, target_real) # how far away from 1 are we\n",
    "\n",
    "        fake_X = gen_Y_to_X(real_Y)\n",
    "        gullibility_to_fake_X = discr_X(fake_X) # 1: tricked that fake_X is real. 0: realizes fake_X is fake  ## ALERT ALERT is this true\n",
    "        loss_GAN_X = criterion_GAN(gullibility_to_fake_X, target_real)\n",
    "\n",
    "        #### Cycle Consistency Loss\n",
    "        allegedly_reconstructed_X = gen_Y_to_X(fake_Y) # complete the cycle\n",
    "        loss_cycle_X = criterion_cycle(allegedly_reconstructed_X, real_X) * CYCLE_WEIGHT\n",
    "\n",
    "        allegedly_reconstructed_Y = gen_X_to_Y(fake_X) # complete the cycle\n",
    "        loss_cycle_Y = criterion_cycle(allegedly_reconstructed_Y, real_Y) * CYCLE_WEIGHT\n",
    "\n",
    "        #### TOTAL Loss\n",
    "        loss_gen = loss_identity_X + loss_identity_Y + loss_GAN_X + loss_GAN_Y + loss_cycle_X + loss_cycle_Y\n",
    "        loss_gen.backward()\n",
    "\n",
    "        optimizer_gen.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_discr_X.zero_grad()\n",
    "\n",
    "#### Real Loss\n",
    "visibility_of_real_X = discr_X(real_X)\n",
    "loss_real_X = criterion_GAN(visibility_of_real_X, target_real)\n",
    "\n",
    "#### Fake Loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NEXT TO DO: TRAINING FROM /Users/peterbanyas/Desktop/ECE 661/Project 661/PyTorch-CycleGAN/train**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "criterion_identity = nn.L1Loss()\n",
    "criterion_cycle = nn.L1Loss()\n",
    "criterion_GAN = nn.MSELoss()\n",
    "\n",
    "# goals:\n",
    "target_X = Tensor(opt.batchSize, opt.input_num_channels, opt.size, opt.size)\n",
    "\n",
    "# When input is already desired output, it should stay the same.\n",
    "def identity_loss(X, Y):\n",
    "    allegedly_same_Y = gen_X_to_Y(Y)\n",
    "    allegedly_same_X = gen_Y_to_X(X)\n",
    "    loss_identity_Y = criterion_identity(Y, allegedly_same_Y)\n",
    "    loss_identity_X = criterion_identity(X, allegedly_same_X)\n",
    "    return ( loss_identity_Y + loss_identity_X ) * IDENTITY_WEIGHT\n",
    "\n",
    "# Appreciate truth, disbelieve lies.\n",
    "def GAN_loss(X, Y, discr_X, ):\n",
    "    fake_Y = gen_X_to_Y(X)\n",
    "    fake_X = gen_Y_to_X(Y)\n",
    "    believe_fake_Y = discr_Y(fake_Y)\n",
    "    believe_fake_X = discr_X(fake_X)\n",
    "    believe_true_Y = discr_Y(Y)\n",
    "    believe_true_X = discr_X(X)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compsci371",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
